{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('data.csv', mode = 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for line in reader:\n",
    "        lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = lines[:2]\n",
    "data = lines[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_data = [line for line in data if line['FL_6_DO'] == 'Behavior|Intent']\n",
    "posterior_data = [line for line in data if line['FL_6_DO'] == 'Intent|Behavior']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_key_rewrite = {\n",
    "    # relationship keys\n",
    "    'P(Text|Relationship)_1': 'P(Friday|Relationship)',\n",
    "    'P(Text|Relationship)_2': 'P(Museum|Relationship)',\n",
    "    'P(Text|Relationship)_3': 'P(Sick|Relationship)',\n",
    "    'P(Text|Relationship)_4': 'P(WYD|Relationship)',\n",
    "    'P(Text|Relationship)_5': 'P(Bored|Relationship)',\n",
    "    'P(Text|Relationship)_6': 'P(Missed Show|Relationship)',\n",
    "    'P(Text|Relationship)_7': 'P(Oolong Tea|Relationship)',\n",
    "    'P(Text|Relationship)_8': 'P(Lunch|Relationship)',\n",
    "    'P(Text|Relationship)_9': 'P(Common Room|Relationship)',\n",
    "    'P(Text|Relationship)_10': 'P(Party|Relationship)',\n",
    "    # friendship keys\n",
    "    'P(Text | Friendship)_1': 'P(Friday|Friendship)',\n",
    "    'P(Text | Friendship)_2': 'P(Museum|Friendship)',\n",
    "    'P(Text | Friendship)_3': 'P(Sick|Friendship)',\n",
    "    'P(Text | Friendship)_4': 'P(WYD|Friendship)',\n",
    "    'P(Text | Friendship)_5': 'P(Bored|Friendship)',\n",
    "    'P(Text | Friendship)_6': 'P(Missed Show|Friendship)',\n",
    "    'P(Text | Friendship)_7': 'P(Oolong Tea|Friendship)',\n",
    "    'P(Text | Friendship)_8': 'P(Lunch|Friendship)',\n",
    "    'P(Text | Friendship)_9': 'P(Common Room|Friendship)',\n",
    "    'P(Text | Friendship)_10': 'P(Party|Friendship)',\n",
    "    # hookup keys\n",
    "    'P(Text | Hookup)_1': 'P(Friday|Hookup)',\n",
    "    'P(Text | Hookup)_2': 'P(Museum|Hookup)',\n",
    "    'P(Text | Hookup)_3': 'P(Sick|Hookup)',\n",
    "    'P(Text | Hookup)_4': 'P(WYD|Hookup)',\n",
    "    'P(Text | Hookup)_5': 'P(Bored|Hookup)',\n",
    "    'P(Text | Hookup)_6': 'P(Missed Show|Hookup)',\n",
    "    'P(Text | Hookup)_7': 'P(Oolong Tea|Hookup)',\n",
    "    'P(Text | Hookup)_8': 'P(Lunch|Hookup)',\n",
    "    'P(Text | Hookup)_9': 'P(Common Room|Hookup)',\n",
    "    'P(Text | Hookup)_10': 'P(Party|Hookup)',\n",
    "}\n",
    "\n",
    "posterior_key_rewrite = {\n",
    "    'Intent | Friday_1': 'P(Friendship|Friday)',\n",
    "    'Intent | Friday_2': 'P(Relationship|Friday)',\n",
    "    'Intent | Friday_3': 'P(Hookup|Friday)',\n",
    "    'Intent | Museum_1': 'P(Friendship|Museum)',\n",
    "    'Intent | Museum_2': 'P(Relationship|Museum)',\n",
    "    'Intent | Museum_3': 'P(Hookup|Museum)',\n",
    "    'Intent | Sick_1': 'P(Friendship|Sick)',\n",
    "    'Intent | Sick_2': 'P(Relationship|Sick)',\n",
    "    'Intent | Sick_3': 'P(Hookup|Sick)',\n",
    "    'Intent | WYD_1': 'P(Friendship|WYD)',\n",
    "    'Intent | WYD_2': 'P(Relationship|WYD)',\n",
    "    'Intent | WYD_3': 'P(Hookup|WYD)',\n",
    "    'Intent | Bored_1': 'P(Friendship|Bored)',\n",
    "    'Intent | Bored_2': 'P(Relationship|Bored)',\n",
    "    'Intent | Bored_3': 'P(Hookup|Bored)',\n",
    "    'Intent | Missed Show_1': 'P(Friendship|Missed Show)',\n",
    "    'Intent | Missed Show_2': 'P(Relationship|Missed Show)',\n",
    "    'Intent | Missed Show_3': 'P(Hookup|Missed Show)',\n",
    "    'Intent | Oolong Tea_1': 'P(Friendship|Oolong Tea)',\n",
    "    'Intent | Oolong Tea_2': 'P(Relationship|Oolong Tea)',\n",
    "    'Intent | Oolong Tea_3': 'P(Hookup|Oolong Tea)',\n",
    "    'Intent | Lunch_1': 'P(Friendship|Lunch)',\n",
    "    'Intent | Lunch_2': 'P(Relationship|Lunch)',\n",
    "    'Intent | Lunch_3': 'P(Hookup|Lunch)',\n",
    "    'Intent | Common Room_1': 'P(Friendship|Common Room)',\n",
    "    'Intent | Common Room_2': 'P(Relationship|Common Room)',\n",
    "    'Intent | Common Room_3': 'P(Hookup|Common Room)',\n",
    "    'Intent | Party_1': 'P(Friendship|Party)',\n",
    "    'Intent | Party_2': 'P(Relationship|Party)',\n",
    "    'Intent | Party_3': 'P(Hookup|Party)',\n",
    "}\n",
    "\n",
    "multi_answer_demographic_keys = ['Race', 'Major']\n",
    "\n",
    "single_answer_demographic_keys = ['Gender', 'Sexuality', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "intify = lambda x: 0 if x == '' else int(x)\n",
    "BUG_FIX_TIME = '2022-12-15 17:00:00'\n",
    "\n",
    "BUG_FIELDS = [\n",
    "    'P(Friendship|Friday)',\n",
    "    'P(Relationship|Friday)',\n",
    "    'P(Hookup|Friday)',\n",
    "    'P(Friendship|Bored)',\n",
    "    'P(Relationship|Bored)',\n",
    "    'P(Hookup|Bored)',\n",
    "    'P(Friendship|Missed Show)',\n",
    "    'P(Relationship|Missed Show)',\n",
    "    'P(Hookup|Missed Show)',\n",
    "]\n",
    "\n",
    "def clean_data(data, is_likelihood):\n",
    "    cleaned = {}\n",
    "    main_keys = likelihood_key_rewrite if is_likelihood else posterior_key_rewrite\n",
    "    cleaned = {new_key: intify(data[key]) for key, new_key in main_keys.items()}\n",
    "    for k in multi_answer_demographic_keys:\n",
    "        cleaned[k] = list(map(int, data[k].split(',')))\n",
    "    for k in single_answer_demographic_keys:\n",
    "        cleaned[k] = int(data[k])\n",
    "    if not is_likelihood:\n",
    "        cleaned['Has Bug'] = data['StartDate'] < BUG_FIX_TIME\n",
    "        if cleaned['Has Bug']:\n",
    "            for k in BUG_FIELDS:\n",
    "                cleaned[k] = 0\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_likelihood_data = [clean_data(data, is_likelihood = True) for data in likelihood_data]\n",
    "cleaned_posterior_data = [clean_data(data, is_likelihood = False) for data in posterior_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_likelihood_keys = list(likelihood_key_rewrite.values())\n",
    "cleaned_posterior_keys = list(posterior_key_rewrite.values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Distribution Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_dist(data, keys):\n",
    "    total = sum(data[k] for k in keys)\n",
    "    for k in keys:\n",
    "        data[k] = 0.0 if total == 0 else data[k] / total\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_keys = [k for k in cleaned_likelihood_keys if k.endswith('Relationship)')]\n",
    "friendship_keys = [k for k in cleaned_likelihood_keys if k.endswith('Friendship)')]\n",
    "hookup_keys = [k for k in cleaned_likelihood_keys if k.endswith('Hookup)')]\n",
    "\n",
    "bored_keys = [k for k in cleaned_posterior_keys if k.endswith('Bored)')]\n",
    "common_room_keys = [k for k in cleaned_posterior_keys if k.endswith('Common Room)')]\n",
    "friday_keys = [k for k in cleaned_posterior_keys if k.endswith('Friday)')]\n",
    "lunch_keys = [k for k in cleaned_posterior_keys if k.endswith('Lunch)')]\n",
    "missed_show_keys = [k for k in cleaned_posterior_keys if k.endswith('Missed Show)')]\n",
    "museum_keys = [k for k in cleaned_posterior_keys if k.endswith('Museum)')]\n",
    "oolong_keys = [k for k in cleaned_posterior_keys if k.endswith('Oolong Tea)')]\n",
    "party_keys = [k for k in cleaned_posterior_keys if k.endswith('Party)')]\n",
    "sick_keys = [k for k in cleaned_posterior_keys if k.endswith('Sick)')]\n",
    "wyd_keys = [k for k in cleaned_posterior_keys if k.endswith('WYD)')]\n",
    "\n",
    "likelihood_keys_set = [relationship_keys, friendship_keys, hookup_keys]\n",
    "posterior_keys_set = [bored_keys, common_room_keys, friday_keys, lunch_keys, missed_show_keys,\n",
    "                      museum_keys, oolong_keys, party_keys, sick_keys, wyd_keys]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_distro_data = []\n",
    "posterior_distro_data = []\n",
    "\n",
    "for data in cleaned_likelihood_data:\n",
    "    for keys in likelihood_keys_set:\n",
    "        data = prob_dist(data, keys)\n",
    "    likelihood_distro_data.append(data)\n",
    "\n",
    "for data in cleaned_posterior_data:\n",
    "    for keys in posterior_keys_set:\n",
    "        data = prob_dist(data, keys)\n",
    "    posterior_distro_data.append(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('likelihood_data.csv', mode = 'w', newline = '') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = likelihood_distro_data[0].keys())\n",
    "    writer.writeheader()\n",
    "    for row in likelihood_distro_data:\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open('posterior_data.csv', mode = 'w', newline = '') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = posterior_distro_data[0].keys())\n",
    "    writer.writeheader()\n",
    "    for row in posterior_distro_data:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bab3bcc10fb4daf3e3f0428a2b3c296eef59ed9157f42dd3480f6eeaabd32d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
